 // public static async SSE(req: Request, res: Response) {
    //     SSEController.setHeaders(res);

    //     const clientId = res.locals.data.id;
    //     const userType = res.locals.userType;
    //     const clientChannel = SSE.channel(userType, clientId);
    //     const streamKey = `user:${userType}:${clientId}:events`;
    //     const group = `user:${userType}:${clientId}:group`;
    //     const consumer = uuid(); // unique per connection
    //     logger.info(`âœ… ${userType} - ${clientId} has connected`);

    //     // Try to create the group (ignore if it exists)
    //     try {
    //         await redisClient.xgroup('CREATE', streamKey, group, '$', 'MKSTREAM');
    //     } catch (err: any) {
    //         if (!err.message.includes('BUSYGROUP')) throw err;
    //     }

    //     let running = true;

    //     const poll = async () => {
    //         while (running) {
    //             try {
    //                 const messages = await redisClient.xreadgroup(
    //                     'GROUP', group, consumer,
    //                     'COUNT', 10,
    //                     'BLOCK', 10000,
    //                     'STREAMS', streamKey, '>'
    //                 ) as [string, [string, string[]][]][];

    //                 if (messages) {
    //                     for (const [, entries] of messages) {
    //                         for (const [id, [, data]] of entries) {
    //                             res.write(`data: ${data}\n\n`);
    //                             await redisClient.xack(streamKey, group, id);
    //                         }
    //                     }
    //                 }
    //             } catch (err) {
    //                 console.error('Redis stream error:', err);
    //                 break;
    //             }
    //         }
    //     };

    //     poll();

    //     req.on('close', async () => {
    //         running = false;
    //         res.end();
    //         await redisClient.xgroup('DELCONSUMER', streamKey, group, consumer);
    //     });
    // }

    // public static async SSE(req: Request, res: Response) {
    //     SSEController.setHeaders(res);

    //     const clientId = res.locals.data.id;
    //     const userType = res.locals.userType;
    //     const streamKey = `user:${clientId}:events`;
    //     const group = `user:${clientId}:group`;
    //     const consumer = uuid();

    //     logger.info(`âœ… ${userType} - ${clientId} connected`);

    //     // Create consumer group if not exists
    //     try {
    //         await redisClient.xgroup('CREATE', streamKey, group, '$', 'MKSTREAM');
    //     } catch (err: any) {
    //         if (!err.message.includes('BUSYGROUP')) throw err;
    //     }

    //     let running = true;

    //     // Fast delivery via Pub/Sub
    //     // const sub = redisClient.duplicate();
    //     // await sub.connect();
    //     // await redisSub.subscribe(`user:${clientId}:pubsub`, (message) => {
    //     //     console.log('ðŸ”” Pub/Sub message received:', message);
    //     //     if (running) res.write(`data: ${message}\n\n`);
    //     // });

    //     const messageHandler = (channel: string, message: string) => {
    //         if (channel === `user:${clientId}:pubsub`) {
    //             const { event, ...data } = JSON.parse(message);
    //             res.write(SSE.write(event, data));
    //         }
    //     };


    //     await SSEController.subscribeToChannel(`user:${clientId}:pubsub`, messageHandler);


    //     // Fallback/reliable delivery via stream
    //     const poll = async () => {
    //         while (running) {
    //             try {
    //                 const messages = await redisClient.xreadgroup(
    //                     'GROUP', group, consumer,
    //                     'COUNT', 10,
    //                     'BLOCK', 10000,
    //                     'STREAMS', streamKey, '>'
    //                 ) as [string, [string, string[]][]][];

    //                 for (const [, entries] of messages ?? []) {
    //                     for (const [id, [, raw]] of entries) {
    //                         console.log(raw);

    //                         const { event, data } = JSON.parse(raw);

    //                         res.write(SSE.write(event, data));
    //                         await redisClient.xack(streamKey, group, id);
    //                     }
    //                 }
    //             } catch (err) {
    //                 logger.error('Redis stream error:', err);
    //                 await new Promise(res => setTimeout(res, 1000));
    //             }
    //         }
    //     };

    //     poll();

    //     // Optional: keep connection alive
    //     const keepAlive = setInterval(() => {
    //         res.write(`: ping\n\n`);
    //     }, 15000);

    //     req.on('close', async () => {
    //         running = false;
    //         clearInterval(keepAlive);
    //         res.end();
    //         await redisSub.unsubscribe(`user:${clientId}:pubsub`);
    //         await redisSub.quit();
    //         await redisClient.xgroup('DELCONSUMER', streamKey, group, consumer);
    //         logger.info(`âŒ ${userType} - ${clientId} disconnected`);
    //     });
    // }

    // public static async SSE(req: Request, res: Response) {
    //     SSEController.setHeaders(res);

    //     const clientId = res.locals.data.id;
    //     const userType = res.locals.userType;
    //     const streamKey = `user:${clientId}:events`;
    //     const group = `user:${clientId}:group`;
    //     const consumer = uuid();
    //     const eventTTL = 3600; // Time-to-live for event IDs in Redis (1 hour)
    //     let running = true;

    //     logger.info(`âœ… ${userType} - ${clientId} connected`);

    //     // Create stream group if not exists
    //     try {
    //         await redisClient.xgroup('CREATE', streamKey, group, '$', 'MKSTREAM');
    //     } catch (err: any) {
    //         if (!err.message.includes('BUSYGROUP')) throw err;
    //     }

    //     // Pub/Sub Fast Delivery
    //     const messageHandler = async (channel: string, message: string) => {
    //         if (channel === `user:${clientId}:pubsub`) {
    //             try {
    //                 const parsed = JSON.parse(message);
    //                 const eventId = parsed.id;

    //                 // Check if the event has already been processed
    //                 const alreadyProcessed = await redisClient.sismember(`user:${clientId}:processed`, eventId);
    //                 if (!alreadyProcessed) {
    //                     res.write(SSE.write(parsed.event, parsed));
    //                     const pipeline = redisClient.pipeline();
    //                     pipeline.sadd(`user:${clientId}:processed`, eventId); // Mark the event as processed
    //                     pipeline.expire(`user:${clientId}:processed`, eventTTL); // Set TTL for cleanup
    //                     pipeline.exec();
    //                 }
    //             } catch (e) {
    //                 logger.error('Failed to parse pubsub message', e);
    //             }
    //         }
    //     };

    //     await SSEController.subscribeToChannel(`user:${clientId}:pubsub`, messageHandler);

    //     // Stream Reliable Fallback
    //     const poll = async () => {
    //         while (running) {
    //             try {
    //                 const messages = await redisClient.xreadgroup(
    //                     'GROUP', group, consumer,
    //                     'COUNT', 10,
    //                     'BLOCK', 10000,
    //                     'STREAMS', streamKey, '>'
    //                 ) as [string, [string, string[]][]][];

    //                 for (const [, entries] of messages ?? []) {
    //                     for (const [id, [, raw]] of entries) {
    //                         try {
    //                             const parsed = JSON.parse(raw);
    //                             const eventId = parsed.id;

    //                             // Check if the event has already been processed
    //                             const alreadyProcessed = await redisClient.sismember(`user:${clientId}:processed`, eventId);
    //                             if (!alreadyProcessed) {
    //                                 console.log("From stream");

    //                                 await redisClient.sadd(`user:${clientId}:processed`, eventId); // Mark the event as processed
    //                                 await redisClient.expire(`user:${clientId}:processed`, eventTTL); // Set TTL for cleanup
    //                                 res.write(SSE.write(parsed.event, parsed));
    //                             }

    //                             await redisClient.xack(streamKey, group, id);
    //                         } catch (e) {
    //                             logger.error('Failed to process stream message', e);
    //                         }
    //                     }
    //                 }
    //             } catch (err) {
    //                 logger.error('Redis stream error:', err);
    //                 await new Promise(res => setTimeout(res, 1000));
    //             }
    //         }
    //     };

    //     poll();

    //     // Ping to keep connection alive
    //     const keepAlive = setInterval(() => {
    //         res.write(`: ping\n\n`);
    //     }, 15000);

    //     // Clean up
    //     req.on('close', async () => {
    //         running = false;
    //         clearInterval(keepAlive);
    //         res.end();
    //         await redisSub.unsubscribe(`user:${clientId}:pubsub`);
    //         await redisSub.quit();
    //         await redisClient.xgroup('DELCONSUMER', streamKey, group, consumer);
    //         logger.info(`âŒ ${userType} - ${clientId} disconnected`);
    //     });
    // }

    // public static async publishSSEEvent(userType: string, clientId: number, event: SSEEvent, key: string = "job") {
    //     const channel = SSE.channel(userType, clientId, key);
    //     try {
    //         const streamKey = `user:${userType}:${clientId}:events`;
    //         // await redisClient.xadd(streamKey, '*', 'data', JSON.stringify(event));
    //         await Promise.all([
    //             redisClient.xadd(`user:${clientId}:events`, '*', 'data', JSON.stringify(event)),
    //             redisPub.publish(`user:${clientId}:pubsub`, JSON.stringify(event)),
    //         ]);
    //         logger.info(`ðŸ¤ Event was successfully published for ${userType} - ${clientId}`);
    //     } catch (error) {
    //         logger.error(`ðŸ›‘ Failed to publish event for ${userType} - ${clientId}`);
    //         console.log(error);
    //     }
    // }

    // public static async publishSSEEvent(userType: string, clientId: number, event: SSEEvent, key: string = "job") {
    //     const channel = SSE.channel(userType, clientId, key);
    //     try {
    //         const streamKey = `user:${userType}:${clientId}:events`;
    //         await redisClient.xadd(streamKey, '*', 'data', JSON.stringify(event));
    //         // await SSE.redisPub.publish(
    //         //     channel,
    //         //     JSON.stringify(event),
    //         // );
    //         logger.info(`ðŸ¤ Event was successfully published for ${userType} - ${clientId}`);
    //     } catch (error) {
    //         logger.error(`ðŸ›‘ Failed to publish event for ${userType} - ${clientId}`);
    //         console.log(error);
    //     }
    // }


private static async subscribeToChannel(
    channel: string,
    messageHandler: (channel: string, message: string) => void
) {
    try {
        const isPattern = channel.includes('*');

        // Choose subscribe or psubscribe based on the channel format
        await new Promise<void>((resolve, reject) => {
            const method = isPattern ? 'psubscribe' : 'subscribe';
            (SSEController.redisSub as any)[method](channel, (err: Error | null) => {
                if (err) {
                    reject(new Error(`Failed to ${method} to ${channel}: ${err.message}`));
                } else {
                    resolve();
                }
            });
        });

        // Attach appropriate message listener
        if (isPattern) {
            SSEController.redisSub.on('pmessage', (_pattern, matchedChannel, message) => {
                if (matchedChannel) {
                    messageHandler(matchedChannel, message);
                }
            });
        } else {
            SSEController.redisSub.on('message', (subscribedChannel, message) => {
                messageHandler(subscribedChannel, message);
            });
        }

    } catch (error: any) {
        logger.error(`Error subscribing to channel "${channel}": ${error.message}`);
        throw error;
    }
}

const cleanUp = async () => {
    try {
        const isPattern = clientChannel.includes('*');

        // Unsubscribe based on subscription type
        if (isPattern) {
            await SSEController.redisSub.punsubscribe(clientChannel);
            SSEController.redisSub.off('pmessage', messageHandler);
        } else {
            await SSEController.redisSub.unsubscribe(clientChannel);
            SSEController.redisSub.off('message', messageHandler);
        }

        // Delete client key and clear heartbeat
        await SSEController.redisBull.del(SSE.clientKey(userType, userId));
        clearInterval(heartbeat);

        logger.info(`ðŸ‘‹ ${userType} - ${userId} has disconnected`);
        res.end();
    } catch (err: any) {
        logger.error(`Error during cleanup: ${err.message}`);
    }
};
